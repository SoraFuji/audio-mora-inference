{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPe/64o7vSYwxkt09coiDhr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoraFuji/audio-mora-inference/blob/main/notebook/inference_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 1) ÂøÖË¶Å„Éë„ÉÉ„Ç±„Éº„Ç∏ÔºàColabÊÉ≥ÂÆöÔºâ\n",
        "!pip -q install webrtcvad tensorflow tensorflow-hub librosa soundfile matplotlib\n",
        "\n",
        "# 2) „Ç§„É≥„Éù„Éº„Éà\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from google.colab import files\n",
        "from IPython.display import Audio, display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 3) ÂÆöÊï∞\n",
        "TARGET_SR        = 16000\n",
        "WINDOW_SEC       = 5\n",
        "SPEECH_THRESHOLD = 0.3\n",
        "OUT_DIR          = \"/content/output_audio_pipeline\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# 4) labels.txt Ë™≠„ÅøËæº„ÅøÔºàGitHub„Åã„ÇâColab„ÅßÈñã„ÅÑ„ÅüÂ†¥Âêà /content „Å´Â≠òÂú®„Åó„Åæ„ÅôÔºâ\n",
        "LABELS_PATH = \"/content/labels.txt\"\n",
        "if not os.path.exists(LABELS_PATH):\n",
        "    print(\"labels.txt „ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇlabels.txt „Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\")\n",
        "    up = files.upload()\n",
        "    if \"labels.txt\" not in up:\n",
        "        raise FileNotFoundError(\"labels.txt „Åå„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åï„Çå„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ\")\n",
        "    LABELS_PATH = \"labels.txt\"\n",
        "\n",
        "class_names = open(LABELS_PATH, \"r\", encoding=\"utf-8\").read().splitlines()\n",
        "print(f\"Loaded labels: {len(class_names)} classes\")\n",
        "\n",
        "# 5) „É¢„Éá„É´„ÇíURL„Åã„Çâ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„Åó„Å¶„É≠„Éº„Éâ\n",
        "MODEL_URL  = \"PASTE_MODEL_URL_HERE\"  # ‚Üê„ÅÇ„Å®„ÅßÂ∑Æ„ÅóÊõø„Åà\n",
        "MODEL_PATH = \"/content/finetuned_moraa_model.h5\"\n",
        "\n",
        "if MODEL_URL == \"PASTE_MODEL_URL_HERE\":\n",
        "    raise ValueError(\"MODEL_URL „Çí„ÅÇ„Å™„Åü„ÅÆÂÖ¨ÈñãURL„Å´Â∑Æ„ÅóÊõø„Åà„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\")\n",
        "\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    !wget -q -O {MODEL_PATH} \"{MODEL_URL}\"\n",
        "\n",
        "print(\"Loading fine-tuned model‚Ä¶\")\n",
        "ft_model = tf.keras.models.load_model(MODEL_PATH, compile=False)\n",
        "\n",
        "# 6) YAMNet„É≠„Éº„Éâ\n",
        "print(\"Loading YAMNet‚Ä¶\")\n",
        "yamnet = hub.load('https://tfhub.dev/google/yamnet/1')\n",
        "\n",
        "# 7) Speech indexÂèñÂæó\n",
        "cm_path = yamnet.class_map_path().numpy().decode()\n",
        "yamnet_labels = open(cm_path, 'r').read().splitlines()\n",
        "speech_idx = next(i for i,lbl in enumerate(yamnet_labels) if 'speech' in lbl.lower())\n",
        "print(f\"‚Üí YAMNet speech index={speech_idx}, label={yamnet_labels[speech_idx]}\")\n",
        "\n",
        "# 8) Âüã„ÇÅËæº„ÅøÊäΩÂá∫ (mean/std/max ‚Üí 3072)\n",
        "def extract_embedding(y):\n",
        "    wav = tf.convert_to_tensor(y, tf.float32)\n",
        "    _, embs, _ = yamnet(wav)\n",
        "    em = embs.numpy()\n",
        "    return np.concatenate([em.mean(0), em.std(0), em.max(0)], axis=0)\n",
        "\n",
        "# 9) Êé®Ë´ñÔºàWAV„Å†„Åë„Ç¢„ÉÉ„Éó„É≠„Éº„ÉâÔºâ\n",
        "print(\"üîΩ Êé®Ë´ñ„Åó„Åü„ÅÑ WAV „Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºàË§áÊï∞OKÔºâ\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded:\n",
        "    if not fn.lower().endswith(\".wav\"):\n",
        "        print(f\"Skip (not wav): {fn}\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\n===== Processing: {fn} =====\")\n",
        "    audio, _ = librosa.load(fn, sr=TARGET_SR, mono=True)\n",
        "\n",
        "    total_sec = len(audio) / TARGET_SR\n",
        "    n_seg     = int(np.ceil(total_sec / WINDOW_SEC))\n",
        "    base      = os.path.splitext(os.path.basename(fn))[0]\n",
        "\n",
        "    for i in range(n_seg):\n",
        "        t0, t1 = i*WINDOW_SEC, min((i+1)*WINDOW_SEC, total_sec)\n",
        "        s, e   = int(t0*TARGET_SR), int(t1*TARGET_SR)\n",
        "        seg    = audio[s:e]\n",
        "\n",
        "        path_raw = f\"{OUT_DIR}/{base}_seg{i+1}_raw.wav\"\n",
        "        sf.write(path_raw, seg, TARGET_SR)\n",
        "\n",
        "        scores, _, _ = yamnet(tf.convert_to_tensor(seg, tf.float32))\n",
        "        avg_scores   = tf.reduce_mean(scores, axis=0).numpy()\n",
        "        sp_prob      = float(avg_scores[speech_idx])\n",
        "\n",
        "        if sp_prob > SPEECH_THRESHOLD:\n",
        "            top5 = []\n",
        "        else:\n",
        "            emb  = extract_embedding(seg)[None, :]\n",
        "            prob = ft_model.predict(emb, verbose=0)[0]\n",
        "            top5 = [(class_names[j], float(prob[j]))\n",
        "                    for j in prob.argsort()[-5:][::-1]]\n",
        "\n",
        "        print(f\"\\n--- Segment {i+1} [{t0:.1f}‚Äì{t1:.1f}s] ---\")\n",
        "        print(f\"‚ñ∂ RAW (speech_prob={sp_prob:.3f})\")\n",
        "        display(Audio(path_raw, rate=TARGET_SR))\n",
        "\n",
        "        if top5:\n",
        "            print(\"  Top-5 Predictions:\")\n",
        "            for cls, sc in top5:\n",
        "                print(f\"    {cls:>8}: {sc:.3f}\")\n",
        "        else:\n",
        "            print(\"  [Speech „Å®Âà§ÂÆö ‚Üí Êé®Ë´ñ„Çπ„Ç≠„ÉÉ„Éó]\")\n",
        "\n",
        "        if top5:\n",
        "            names = [cls for cls, _ in top5]\n",
        "            scores_vals = [sc for _, sc in top5]\n",
        "            x = np.arange(len(names))\n",
        "            fig, ax = plt.subplots(figsize=(6,4))\n",
        "            ax.bar(x, scores_vals, 0.6)\n",
        "            ax.set_xticks(x)\n",
        "            ax.set_xticklabels(names, rotation=45, ha='right')\n",
        "            ax.set_ylim(0,1)\n",
        "            ax.set_title(f\"Segment {i+1} Top-5 Predictions\")\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n"
      ],
      "metadata": {
        "id": "T_cCoh9JXHew"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}